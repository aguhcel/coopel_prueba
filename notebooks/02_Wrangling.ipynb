{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f27b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "from itables import init_notebook_mode\n",
    "\n",
    "init_notebook_mode(all_interactive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1673fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos\n",
    "try:\n",
    "    df = pd.read_csv('../data/transacciones_retail.csv', encoding='utf-8')\n",
    "except UnicodeDecodeError:\n",
    "    print(\"except\")\n",
    "    df = pd.read_csv('../data/transacciones_retail.csv', encoding='ISO-8859-1')\n",
    "\n",
    "print(\"Datos cargados exitosamente.\")\n",
    "print(\"Forma del dataset:\", df.shape)\n",
    "print(\"\\nPrimeras 5 filas:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e949f934",
   "metadata": {},
   "source": [
    "Por prioridad se atenderan los siguientes puntos:\n",
    "\n",
    "1. Datos Duplicados\n",
    "2. Datos Faltantes\n",
    "3. Datos desbalanceados\n",
    "4. Datos sesgados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db30e40",
   "metadata": {},
   "source": [
    "## 1. Análisis de los datos los duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95119ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_duplicates = df[df.duplicated()]\n",
    "all_duplicates = df[df.duplicated(keep=False)]\n",
    "\n",
    "print(f\"# of rows duplicates: {len(df_duplicates)}\")\n",
    "print(f\"All of rows duplicates: {len(all_duplicates)}\")\n",
    "print(f\"Unique rows: {df.shape[0] - df_duplicates.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b8b416",
   "metadata": {},
   "source": [
    "### Eliminamos Duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05477702",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd73bdaa",
   "metadata": {},
   "source": [
    "## 2. Análisis de los datos nulos\n",
    "\n",
    "<img src=\"../reports/imgs/missing_values.png\" alt=\"Datos imbalanceados\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edefa686",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_stats = df.groupby(\"Country\").agg({\n",
    "    'CustomerID': ['count', 'nunique'],\n",
    "    'InvoiceNo': 'nunique',\n",
    "    'Quantity': 'sum'\n",
    "}).round(2)\n",
    "\n",
    "country_stats.columns = ['Total_Transacciones', 'Clientes_Unicos', 'Facturas_Unicas', 'Cantidad_Total']\n",
    "country_stats = country_stats.sort_values('Total_Transacciones', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23566447",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 10 países por número de transacciones:\")\n",
    "country_stats.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c58457b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ultimos 10 países por número de transacciones:\")\n",
    "country_stats.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d816c493",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"Country == 'Hong Kong'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd7d55f",
   "metadata": {},
   "source": [
    "Hong kong no tiene clientes unicos ni transacciones, pero si muchos productos vendidos!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099cf505",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"Country == 'Hong Kong'\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9061176",
   "metadata": {},
   "outputs": [],
   "source": [
    "customerId_null = df.groupby('Country').agg({\n",
    "    'CustomerID': ['count', lambda x: x.isnull().sum(), 'nunique']\n",
    "}).round(2)\n",
    "\n",
    "customerId_null.columns = ['Total_Transacciones', 'CustomerID_Nulos', 'Clientes_Unicos']\n",
    "customerId_null['Porcentaje_nulls'] = (customerId_null['CustomerID_Nulos'] / customerId_null['Total_Transacciones'] * 100).round(2)\n",
    "\n",
    "# Ordenar por número de nulls descendente\n",
    "customerId_null = customerId_null.sort_values('CustomerID_Nulos', ascending=False)\n",
    "\n",
    "print(\"=== ANÁLISIS DE CUSTOMERID NULOS POR PAÍS ===\")\n",
    "customerId_null[customerId_null['CustomerID_Nulos'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7151afcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_problems = df.groupby('Country').agg({\n",
    "    'CustomerID': lambda x: x.isnull().sum()\n",
    "}).query('CustomerID > 0').sort_values('CustomerID', ascending=False)\n",
    "\n",
    "print(\"Países con CustomerID nulos:\")\n",
    "for country, nulls in country_problems['CustomerID'].items():\n",
    "    total = len(df[df['Country'] == country])\n",
    "    percent = (nulls / total) * 100\n",
    "    print(f\"  {country}: {nulls} nulos de {total} transacciones ({percent:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c7540a",
   "metadata": {},
   "source": [
    "Si bien, desde el incio se observo que CustomerID, tenia varios datos nulos, se indago un poco más. Tomando en consideración las tracciones realizadas por los clientes.\n",
    "\n",
    "Si bien, un pais a considerar es Hong Kong, con 284 registros. Sin embargo tiene los registros de CustomerID nulos. Ademas de este se observa que hay otros paises con una problematica similar. Sin embargo, se obta por eliminar aquellos registros que tienen como nulo CustomerID. Ya que el problema de negocio es el siguiente:\n",
    "\n",
    "Construir un modelo que pueda predecir si un **cliente existente** volverá a comprar en el futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3471d477",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['CustomerID'].notna()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15e91b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe037b6",
   "metadata": {},
   "source": [
    "# 3. Análisis Datos Desbalanceados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89825b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== ANÁLISIS DE DESBALANCE EN COUNTRY ===\")\n",
    "\n",
    "country_distribution = df['Country'].value_counts()\n",
    "total_transactions = len(df)\n",
    "\n",
    "print(f\"Total de países: {len(country_distribution)}\")\n",
    "print(f\"Total de transacciones: {total_transactions}\")\n",
    "\n",
    "\n",
    "print(f\"\\nTop 5 países concentran: {country_distribution.head(5).sum() / total_transactions * 100:.1f}% de las transacciones\")\n",
    "print(f\"UK concentra: {country_distribution['United Kingdom'] / total_transactions * 100:.1f}% de las transacciones\")\n",
    "\n",
    "\n",
    "print(\"\\nDistribución por país:\")\n",
    "for i, (country, count) in enumerate(country_distribution.head(10).items()):\n",
    "    percent = (count / total_transactions) * 100\n",
    "    print(f\"{i+1:2d}. {country}: {count:,} ({percent:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1836bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clasificar por tiers\n",
    "\n",
    "def classify_countries_by_volume(df):\n",
    "    country_stats = df['Country'].value_counts()\n",
    "    \n",
    "    # Definir tiers\n",
    "    tier1 = country_stats[country_stats >= 1000]      # Países principales\n",
    "    tier2 = country_stats[(country_stats >= 100) & (country_stats < 1000)]  # Países medianos\n",
    "    tier3 = country_stats[country_stats < 100]        # Países pequeños\n",
    "    \n",
    "    print(\"=== CLASIFICACIÓN POR TIERS ===\")\n",
    "    print(f\"Tier 1 (>=1000 trans): {len(tier1)} países - {tier1.sum():,} transacciones\")\n",
    "    print(f\"Tier 2 (100-999 trans): {len(tier2)} países - {tier2.sum():,} transacciones\")\n",
    "    print(f\"Tier 3 (<100 trans): {len(tier3)} países - {tier3.sum():,} transacciones\")\n",
    "    \n",
    "    return {\n",
    "        'tier1': tier1.index.tolist(),\n",
    "        'tier2': tier2.index.tolist(), \n",
    "        'tier3': tier3.index.tolist()\n",
    "    }\n",
    "\n",
    "# Agregar columna de tier al dataset\n",
    "def assign_tier(country):\n",
    "    if country in tiers['tier1']:\n",
    "        return 'Tier1_Principal'\n",
    "    elif country in tiers['tier2']:\n",
    "        return 'Tier2_Mediano'\n",
    "    else:\n",
    "        return 'Tier3_Pequeño'\n",
    "\n",
    "tiers = classify_countries_by_volume(df)\n",
    "\n",
    "df['Country_Tier'] = df['Country'].apply(assign_tier)\n",
    "print(\"\\nDistribución por tiers:\")\n",
    "df['Country_Tier'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f661ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate_countries(df, umbral_minimo=100):\n",
    "    country_counts = df['Country'].value_counts()\n",
    "    \n",
    "    # Países principales (por encima del umbral)\n",
    "    main_countries = country_counts[country_counts >= umbral_minimo].index.tolist()\n",
    "    \n",
    "    # Crear nueva columna\n",
    "    df['Country_Consolidated'] = df['Country'].apply(\n",
    "        lambda x: x if x in main_countries else 'Other_Countries'\n",
    "    )\n",
    "    \n",
    "    print(f\"=== CONSOLIDACIÓN DE PAÍSES (umbral: {umbral_minimo}) ===\")\n",
    "    print(f\"Países principales: {len(main_countries)}\")\n",
    "    print(f\"Países agrupados en 'Other': {len(country_counts) - len(main_countries)}\")\n",
    "    \n",
    "    consolidation_stats = df['Country_Consolidated'].value_counts()\n",
    "    print(f\"\\nDistribución consolidada:\")\n",
    "    for country, count in consolidation_stats.items():\n",
    "        percent = (count / len(df)) * 100\n",
    "        print(f\"  {country}: {count:,} ({percent:.1f}%)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = consolidate_countries(df, umbral_minimo=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4594049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar por regiones geográficas\n",
    "def make_regions(country):\n",
    "    \"\"\"Mapear países a regiones\"\"\"\n",
    "    europe = ['United Kingdom', 'Germany', 'France', 'Spain', 'Netherlands', \n",
    "              'Belgium', 'Switzerland', 'Austria', 'Italy', 'Portugal', 'Norway',\n",
    "              'Denmark', 'Finland', 'Sweden', 'Poland', 'Cyprus']\n",
    "    \n",
    "    asia_pacific = ['Australia', 'Japan', 'Singapore', 'Hong Kong']\n",
    "    \n",
    "    americas = ['USA', 'Canada', 'Brazil']\n",
    "    \n",
    "    if country in europe:\n",
    "        return 'Europa'\n",
    "    elif country in asia_pacific:\n",
    "        return 'Asia_Pacífico'\n",
    "    elif country in americas:\n",
    "        return 'Américas'\n",
    "    else:\n",
    "        return 'Otros'\n",
    "\n",
    "df['Region'] = df['Country'].apply(make_regions)\n",
    "\n",
    "print(\"=== DISTRIBUCIÓN POR REGIÓN ===\")\n",
    "region_stats = df['Region'].value_counts()\n",
    "for region, count in region_stats.items():\n",
    "    percent = (count / len(df)) * 100\n",
    "    print(f\"{region}: {count:,} ({percent:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0820949d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Top 10 países\n",
    "top_countries = df['Country'].value_counts().head(10)\n",
    "axes[0,0].bar(range(len(top_countries)), top_countries.values)\n",
    "axes[0,0].set_title('Top 10 Países por Transacciones')\n",
    "axes[0,0].set_xticks(range(len(top_countries)))\n",
    "axes[0,0].set_xticklabels(top_countries.index, rotation=45)\n",
    "\n",
    "# 2. Distribución por tiers\n",
    "tier_counts = df['Country_Tier'].value_counts()\n",
    "axes[0,1].pie(tier_counts.values, labels=tier_counts.index, autopct='%1.1f%%')\n",
    "axes[0,1].set_title('Distribución por Tiers de País')\n",
    "\n",
    "# 3. Distribución por región\n",
    "region_counts = df['Region'].value_counts()\n",
    "axes[1,0].pie(region_counts.values, labels=region_counts.index, autopct='%1.1f%%')\n",
    "axes[1,0].set_title('Distribución por Región')\n",
    "\n",
    "# 4. Países consolidados\n",
    "consol_counts = df['Country_Consolidated'].value_counts()\n",
    "axes[1,1].bar(range(len(consol_counts)), consol_counts.values)\n",
    "axes[1,1].set_title('Países Consolidados')\n",
    "axes[1,1].set_xticks(range(len(consol_counts)))\n",
    "axes[1,1].set_xticklabels(consol_counts.index, rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ff1e9d",
   "metadata": {},
   "source": [
    "Obteniendo estos datos se obta por un filtrado conbinado para que el conjunto de datos este lo más balanceado posible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43fa1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter = df[\n",
    "    (df['Country_Tier'].isin(['Tier1_Principal', 'Tier2_Mediano'])) &\n",
    "    (df['Region'].isin(['Europa', 'Asia_Pacífico', 'Américas']))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e6e5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== FILTRADO COMBINADO ===\")\n",
    "print(f\"Dataset original: {df.shape[0]} filas\")\n",
    "print(f\"Dataset filtrado (Tier 1+2 + Regiones principales): {df_filter.shape[0]} filas\")\n",
    "print(f\"Filas eliminadas: {df.shape[0] - df_filter.shape[0]}\")\n",
    "print(f\"Porcentaje mantenido: {(df_filter.shape[0] / df.shape[0]) * 100:.1f}%\")\n",
    "\n",
    "print(\"\\nDistribución final por tiers:\")\n",
    "print(df_filter['Country_Tier'].value_counts())\n",
    "\n",
    "print(\"\\nDistribución final por regiones:\")\n",
    "print(df_filter['Region'].value_counts())\n",
    "\n",
    "print(f\"\\nClientes únicos después del filtrado: {df_filter['CustomerID'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0237a976",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== VALIDACIÓN DEL FILTRADO ===\")\n",
    "\n",
    "# Verificar balance después del filtrado\n",
    "print(\"Distribución por tiers (más balanceada):\")\n",
    "tier_dist = df['Country_Tier'].value_counts(normalize=True) * 100\n",
    "for tier, pct in tier_dist.items():\n",
    "    print(f\"  {tier}: {pct:.1f}%\")\n",
    "\n",
    "print(\"\\nDistribución por regiones (más balanceada):\")\n",
    "region_dist = df['Region'].value_counts(normalize=True) * 100\n",
    "for region, pct in region_dist.items():\n",
    "    print(f\"  {region}: {pct:.1f}%\")\n",
    "\n",
    "# Verificar que no perdimos demasiados clientes\n",
    "clients_by_country = df.groupby('Country')['CustomerID'].nunique().sort_values(ascending=False)\n",
    "print(f\"\\nTop 5 países por clientes únicos:\")\n",
    "clients_by_country.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087953d9",
   "metadata": {},
   "source": [
    "## 4. Análisis de los Datos sesgados\n",
    "\n",
    "Se trabajara con la columna UnitPrice, ya que es la que tiene un sego muy alto (γ1 = 186.50).\n",
    "\n",
    "<img src=\"../reports/imgs/unitprice.png\" alt=\"Datos imbalanceados\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251c04bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Estadísticas descriptivas de UnitPrice:\")\n",
    "print(df['UnitPrice'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1779df9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = stats.skew(df['UnitPrice'])\n",
    "kurtosis = stats.kurtosis(df['UnitPrice'])\n",
    "\n",
    "print(f\"\\nMedidas de forma:\")\n",
    "print(f\"Sesgo (skewness): {bias:.2f}\")\n",
    "print(f\"Curtosis (kurtosis): {kurtosis:.2f}\")\n",
    "\n",
    "# Identificar outliers\n",
    "Q1 = df['UnitPrice'].quantile(0.25)\n",
    "Q3 = df['UnitPrice'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_limit = Q1 - 1.5 * IQR\n",
    "upper_limit = Q3 + 1.5 * IQR\n",
    "\n",
    "outliers = df[(df['UnitPrice'] < lower_limit) | (df['UnitPrice'] > upper_limit)]\n",
    "print(f\"\\nOutliers detectados: {len(outliers)} ({len(outliers)/len(df)*100:.2f}%)\")\n",
    "print(f\"Rango normal: {lower_limit:.2f} - {upper_limit:.2f}\")\n",
    "print(f\"Valor máximo: {df['UnitPrice'].max():.2f}\")\n",
    "print(f\"Valor mínimo: {df['UnitPrice'].min():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8f2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# 1. Distribución original\n",
    "axes[0,0].hist(df['UnitPrice'], bins=50, alpha=0.7, color='blue')\n",
    "axes[0,0].set_title('Distribución Original de UnitPrice')\n",
    "axes[0,0].set_xlabel('UnitPrice')\n",
    "axes[0,0].set_ylabel('Frecuencia')\n",
    "\n",
    "# 2. Boxplot original\n",
    "axes[0,1].boxplot(df['UnitPrice'])\n",
    "axes[0,1].set_title('Boxplot Original')\n",
    "axes[0,1].set_ylabel('UnitPrice')\n",
    "\n",
    "# 3. QQ Plot original\n",
    "stats.probplot(df['UnitPrice'], dist=\"norm\", plot=axes[0,2])\n",
    "axes[0,2].set_title('Q-Q Plot Original')\n",
    "\n",
    "# 4. Distribución sin outliers extremos\n",
    "unitprice_clean = df[df['UnitPrice'] <= df['UnitPrice'].quantile(0.95)]['UnitPrice']\n",
    "axes[1,0].hist(unitprice_clean, bins=50, alpha=0.7, color='green')\n",
    "axes[1,0].set_title('Distribución sin Outliers Extremos (95%)')\n",
    "axes[1,0].set_xlabel('UnitPrice')\n",
    "axes[1,0].set_ylabel('Frecuencia')\n",
    "\n",
    "# 5. Transformación logarítmica\n",
    "unitprice_log = np.log1p(df[df['UnitPrice'] > 0]['UnitPrice'])\n",
    "axes[1,1].hist(unitprice_log, bins=50, alpha=0.7, color='red')\n",
    "axes[1,1].set_title('Distribución Log-transformada')\n",
    "axes[1,1].set_xlabel('Log(UnitPrice + 1)')\n",
    "axes[1,1].set_ylabel('Frecuencia')\n",
    "\n",
    "# 6. Transformación de raíz cuadrada\n",
    "unitprice_sqrt = np.sqrt(df[df['UnitPrice'] >= 0]['UnitPrice'])\n",
    "axes[1,2].hist(unitprice_sqrt, bins=50, alpha=0.7, color='orange')\n",
    "axes[1,2].set_title('Distribución Raíz Cuadrada')\n",
    "axes[1,2].set_xlabel('√UnitPrice')\n",
    "axes[1,2].set_ylabel('Frecuencia')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691d27c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_filtering = df[\n",
    "    (df['Country_Tier'].isin(['Tier1_Principal', 'Tier2_Mediano'])) &\n",
    "    (df['Region'].isin(['Europa', 'Asia_Pacífico', 'Américas']))\n",
    "].copy()\n",
    "\n",
    "print(\"=== FILTRADO COMBINADO ===\")\n",
    "print(f\"Dataset original: {df.shape[0]} filas\")\n",
    "print(f\"Dataset filtrado (Tier 1+2 + Regiones principales): {df_final_filtering.shape[0]} filas\")\n",
    "print(f\"Filas eliminadas: {df.shape[0] - df_final_filtering.shape[0]}\")\n",
    "print(f\"Porcentaje mantenido: {(df_final_filtering.shape[0] / df.shape[0]) * 100:.1f}%\")\n",
    "\n",
    "print(\"\\nDistribución final por tiers:\")\n",
    "print(df_final_filtering['Country_Tier'].value_counts())\n",
    "\n",
    "print(\"\\nDistribución final por regiones:\")\n",
    "print(df_final_filtering['Region'].value_counts())\n",
    "\n",
    "print(f\"\\nClientes únicos después del filtrado: {df_final_filtering['CustomerID'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad2f240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_strategy(df):\n",
    "    \"\"\"Aplicar estrategia final para datos sesgados\"\"\"\n",
    "    \n",
    "    print(\"=== ESTRATEGIA FINAL PARA DATOS SESGADOS ===\")\n",
    "    \n",
    "    # 1. Crear transformación logarítmica para modelado\n",
    "    df['UnitPrice_Log'] = np.log1p(df['UnitPrice'])\n",
    "    \n",
    "    # 2. Aplicar winsorización para outliers extremos\n",
    "    p99 = df['UnitPrice'].quantile(0.99)\n",
    "    p1 = df['UnitPrice'].quantile(0.01)\n",
    "    df['UnitPrice_Clean'] = df['UnitPrice'].clip(lower=p1, upper=p99)\n",
    "    \n",
    "    # 3. Crear segmentos de precios para análisis categórico\n",
    "    # (ya se aplicó arriba)\n",
    "    \n",
    "    # 4. Crear variable de valor total\n",
    "    df['TotalValue'] = df['Quantity'] * df['UnitPrice']\n",
    "    df['TotalValue_Log'] = np.log1p(df['TotalValue'].clip(lower=0))\n",
    "    \n",
    "    print(\"Variables creadas:\")\n",
    "    print(\"- UnitPrice_Log: Para modelado ML\")\n",
    "    print(\"- UnitPrice_Clean: Outliers controlados\")\n",
    "    print(\"- Price_Segment: Para análisis categórico\")\n",
    "    print(\"- TotalValue_Log: Valor total transformado\")\n",
    "    \n",
    "    # Verificar mejora en sesgo\n",
    "    bias_original = stats.skew(df['UnitPrice'])\n",
    "    bias_log = stats.skew(df['UnitPrice_Log'])\n",
    "    bias_clean = stats.skew(df['UnitPrice_Clean'])\n",
    "    \n",
    "    print(f\"\\n=== MEJORA EN SESGO ===\")\n",
    "    print(f\"Original: {bias_original:.3f}\")\n",
    "    print(f\"Log-transformado: {bias_log:.3f}\")\n",
    "    print(f\"Winsorizado: {bias_clean:.3f}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Aplicar estrategia final\n",
    "df = final_strategy(df_final_filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29be4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas finales\n",
    "print(f\"\\nDataset final:\")\n",
    "print(f\"Filas: {df.shape[0]}\")\n",
    "print(f\"Columnas: {df.shape[1]}\")\n",
    "\n",
    "# Verificar que no hay valores nulos en las transformaciones\n",
    "print(f\"\\nValores nulos en transformaciones:\")\n",
    "for col in ['UnitPrice_Log', 'UnitPrice_Clean', 'TotalValue_Log']:\n",
    "    if col in df.columns:\n",
    "        nulls = df[col].isnull().sum()\n",
    "        print(f\"{col}: {nulls} nulos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96e2ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c857c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/data_wrangling.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
